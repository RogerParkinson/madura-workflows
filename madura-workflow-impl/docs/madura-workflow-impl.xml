<?xml-stylesheet type="text/xsl" href="MaduraHTML.xsl" ?>
<doc xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:noNamespaceSchemaLocation="https://oss.sonatype.org/content/repositories/releases/nz/co/senanque/maduradocs/6.1.0/maduradocs-6.1.0.xsd">
	<title>
		<MainTitle>MaduraWorkflowImpl</MainTitle>
		<SubTitle>User Guide</SubTitle>
		<Author>Roger Parkinson</Author>
		<Revision>$Revision: 1$</Revision>
		<image>logo.jpg</image>
		<references>
			<reference url="http://www.atomikos.com/" t="Atomikos" />
			<reference url="http://tomcat.apache.org/" t="Tomcat" />
			<reference url="http://www.h2database.com" t="H2" />
			<reference url="https://vaadin.com/home" t="Vaadin" />
			<reference url="https://github.com/RogerParkinson/madura-vaadin-support/tree/master/madura-login" t="Madura Login" />
			<reference url="https://github.com/RogerParkinson/madura-objects-parent/tree/master/madura-utils" t="Madura Utils" />
			<reference url="https://github.com/RogerParkinson/madura-objects-parent" t="Madura Objects" />
			<reference url="https://github.com/RogerParkinson/madura-vaadin-support" t="Madura Vaadin Support" />
			<reference url="https://github.com/RogerParkinson/madura-objects-parent/tree/master/madura-rules"  t="Madura Rules" />
			<reference url="https://github.com/RogerParkinson/madura-bundles/tree/master/madura-bundle" t="Madura Bundles" />
			<reference url="https://github.com/RogerParkinson/madura-workflows" t="Madura Workflow" />
			<reference url="https://github.com/RogerParkinson/madura-workflows/tree/master/madura-workflow-impl" t="Madura Workflow Impl" />
			<reference url="http://www.apache.org/licenses/LICENSE-2.0" t="Apache Licence 2.0" />
			<reference url="http://www.springsource.org/" t="Spring Framework" />
		</references>
	</title>
	<body>
		<process-log />
		<process-references />
		<h1 t="What is this?">
			<h2 t="What do you mean: Workflow?">
			<p>If you need an application that, say, just has a user fill in a form and save the results to a database then you do not need workflow. However, if
			you need an application that has a user fill in one of several forms, each of which has dynamic validation, then passes the result to another
			user who operates it using another form (also with dynamic validation) and then perhaps send the result to an external service that returns
			information that is then integrated into the result, and all this might take several days or weeks to complete, then you probably do need workflow.
			If, in addition, there are conditions and timeouts that route the results to a supervisor for review, and there are hundreds if not thousands of these
			things going through the system at once then you almost certainly do need workflow.</p>
			</h2>
			<h2 t="So what does this do?">
			<p>This is a sample application showing what can be built onto Madura Workflow<referenceLink t="Madura Workflow"/>.</p>
			<p>Madura Workflow is a workflow engine rather than an application, consequently it leaves a number of implementation decisions open. Those decisions
			are addressed here. The sample application is somewhere between a demo and production code. With a few tweaks it could be used in production
			and part of this document explores those tweaks and further ways to extend the application.</p>
			<p>Over and above the workflow engine this application provides the following:</p>
			<list>
			<le>A full UI implemented in Vaadin which allows users to launch and manage process instances.</le>
			<le>Security which provides a login and associated permissions. The permissions
			are used to restrict users' access to certain queues and process instances.</le>
			<le>A way to deploy new process definitions on the fly using Madura Bundles<referenceLink t="Madura Bundles"/>. The bundles also contain all associated
			resources, such as forms, messages, object definitions and custom code.</le>
			<le>A JPA database implementation, including a two phase commit transaction supporter (Atomikos<referenceLink t="Atomikos"/>). The configuration for this is worth reviewing.</le>
			<le>Integration with Madura Rules<referenceLink t="Madura Rules"/>. This means the objects defined in the process definitions can have
			rules attached to them. The forms and other interactions with these objects will automatically invoke the rules. This greatly simplifies the
			code that you would otherwise have to write for the UI and message handling.</le>
			<le>Scheduling based on Spring's<referenceLink t="Spring Framework"/> <courier>task:scheduler</courier> namespace which by default uses <courier>ScheduledThreadPoolExecutor</courier>.</le>
			<le>JMX integration which allows you to monitor some lower level facilities.</le>
			<le>Deployment in an application server, in this case Tomcat<referenceLink t="Tomcat"/>, but no Tomcat-specific
			services are used so it ought to run on any JEE compliant server.</le>
			<le>A locking protocol which manages locks across the system.</le>
			</list>
			<p>Each of these is discussed in more detail below, as well as some ways to extend the application or invoke Madura Workflow in other ways.</p>
			</h2>
			</h1>
			<h1 t="Running the application">
			<p>The README.md file in <referenceLink t="Madura Workflow"/> gives information about deploying this, including some minor but necessary
			configuration.</p>
			<p>You will need an application server. We tested this with Tomcat V7, but any application server you are comfortable with
			should be just fine. It also runs on VMWare's cloud server, and probably most others. Make sure you are running
			Java 7 or later.</p>
			<p>When you start your application server the console log will show some warnings:</p>
			<code><![CDATA[
14:14:07.813 [localhost-startStop-1] WARN  c.a.i.c.UserTransactionServiceImp - Slf4jLogger.java:12 No properties path set - looking for transactions.properties in classpath...
14:14:07.816 [localhost-startStop-1] WARN  c.a.i.c.UserTransactionServiceImp - Slf4jLogger.java:12 Using init file: /home/roger/madura-workflows/.metadata/.plugins/org.eclipse.wst.server.core/tmp0/wtpwebapps/madura-workflow-impl/WEB-INF/classes/transactions.properties
14:14:08.064 [localhost-startStop-1] WARN  c.a.jdbc.AbstractDataSourceBean - Slf4jLogger.java:12 AtomikosDataSoureBean 'pu__workflow': poolSize equals default - this may cause performance problems!
14:14:09.460 [localhost-startStop-1] WARN  o.s.b.f.s.DefaultListableBeanFactory - AbstractBeanFactory.java:1480 Bean creation exception on FactoryBean type check: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'workflowManager': Cannot resolve reference to bean 'bundleManager' while setting bean property 'bundleManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'bundleManager' defined in ServletContext resource [/WEB-INF/applicationContext.xml]: Cannot resolve reference to bean 'errorEndpoint' while setting bean property 'exportedBeans' with key [TypedStringValue: value [errorEndpoint], target type [null]]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'errorEndpoint': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private nz.co.senanque.workflow.WorkflowManager nz.co.senanque.messaging.ErrorEndpoint.m_workflowManager; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [nz.co.senanque.workflow.WorkflowManager] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
14:14:10.015 [localhost-startStop-1] WARN  c.a.jdbc.AbstractDataSourceBean - Slf4jLogger.java:12 AtomikosDataSoureBean 'nmc-workflow-1.0.2-SNAPSHOT': poolSize equals default - this may cause performance problems!
14:14:10.504 [localhost-startStop-1] INFO  n.c.s.m.b.BundleMangerDelegateJar - BundleMangerDelegateJar.java:90 Added bundle: nmc-workflow-1.0.2-SNAPSHOT.jar
14:14:12.278 [localhost-startStop-1] WARN  c.a.jdbc.AbstractDataSourceBean - Slf4jLogger.java:12 AtomikosDataSoureBean 'order-workflow-1.0.2-SNAPSHOT': poolSize equals default - this may cause performance problems!
14:14:13.042 [localhost-startStop-1] INFO  n.c.s.m.b.BundleMangerDelegateJar - BundleMangerDelegateJar.java:90 Added bundle: order-workflow-1.0.2-SNAPSHOT.jar
14:14:13.131 [localhost-startStop-1] WARN  c.a.jdbc.AbstractDataSourceBean - Slf4jLogger.java:12 AtomikosDataSoureBean 'simple-workflow-1.0.2-SNAPSHOT': poolSize equals default - this may cause performance problems!
14:14:13.344 [localhost-startStop-1] INFO  n.c.s.m.b.BundleMangerDelegateJar - BundleMangerDelegateJar.java:90 Added bundle: simple-workflow-1.0.2-SNAPSHOT.jar
14:14:13.420 [localhost-startStop-1] WARN  c.v.s.navigator.SpringViewProvider - SpringViewProvider.java:165 No SpringViews found
				]]></code>
			<p>These are all normal and do not cause problems, though the poolSize should be reviewed before going into production. The
			<courier>DefaultListableBeanFactory</courier> looks a little alarming but it is benign.</p>
			<p>Browse to <courier>http://localhost:8080/madura-workflow-impl/</courier>
			(your server name and port may vary if you are not running a default configured Tomcat on your local machine). You should see a
			login page.</p>
			<img width="12cm" href="images/login.png">Login</img>
			<p>The username/password is admin/admin.</p>
			<img width="12cm" href="images/loggedin.png">Home-1</img>
			<p>This is the home screen, the one every user reaches just after login. It is mostly taken up by the Processes table which shows
			all the processes this user is allowed to see. Since we logged in as admin (who has ADMIN permission) we can see (but not necessarily edit) everything,
			and there is a process instance in the table with the status DONE, which means it ran to completion. Ordinary users only see
			process instances they are able to do something with so they do not see DONE processes. When you run your copy for the first time you will
			not see the DONE process.</p>
			<p>The next step is to launch a new process instance. Click on File->Launch and you will see the Launch Wizard.</p>
			<img width="12cm" href="images/LaunchWizard.png">LaunchWizard</img>
			<p>The Launch Wizard shows a list of all the process definitions in the system that this user is allowed to launch. Because this
			user has ADMIN permission that means all of them. Other users might see a shorter list or none at all. In fact this is
			not the full list of process definitions anyway. There might be multiple versions of each of these processes and only the
			latest versions are presented because we cannot launch old versions. Also some process definitions are not directly launchable,
			they can only be launched by another process so they are not included either.</p>
			<p>Just clicking on one of the process definitions will show its launch form. Click on the first one, the Demo process.</p>
			<p>Before going any further we should look at what this process does. The definition of the process is in the <courier>order-workflow</courier>
			sub project in the file <courier>src/main/resources/OrderWorkflow.wrk</courier>:</p>
				<code><![CDATA[
process: Order "Demo" "This is the demo process" launchForm=LaunchDemo  queue="Q1"{
	try {
		message=orderMessageSender;
	}
	catch (abort) {
		compute=temperatureCompute;
	}
	form=DisplayFahrenheit queue="Q1";
}  
				]]></code>
			<p>This is a trivial example of a process. It starts with a launch form which we will see next. Once underway it tries to send a message
			to an external web service. The web service converts Fahrenheit to Celsuis, total overkill for this kind of software, but it does give us
			an understandable sequence to work through. If the web service fails the compute task is performed and this just runs some Java code to
			convert the temperature.</p>
			<p>Finally the process shows a form that displays the converted temperature.</p>
			<p>The two forms could be custom written in Java using Vaadin, but this takes the lazy approach and just generates the Vaadin form from
			the underlying object. The underlying object is, of course, a Madura Object and includes rich metadata, so this is more functional that you
			might suppose. The following form definitions can be found in <courier>src/main/resources/order-workflow-context.xml</courier></p>
				<code><![CDATA[
<bean id="VaadinLaunchDemo" class="nz.co.senanque.workflow.VaadinLaunchForm" scope="prototype">
	<property name="referenceName" value="orderName"/>
	<property name="fieldList">
		<list>
			<value>orderName</value>
    		<value>fahrenheit</value>
    	</list>
    </property>
</bean>
<bean id="VaadinDisplayFahrenheit" class="nz.co.senanque.workflow.VaadinLaunchForm" scope="prototype">
   	<property name="fieldList">
   		<list>
   			<value>celsius</value>
   		</list>
   	</property>
</bean>
				]]></code>
			<p>Using the <courier>fieldList</courier> property we show only the fields we are interested in.</p>
			<p>The message definition (in the same file) looks like this:</p>
				<code><![CDATA[
<bean id="orderMessageSender" class="nz.co.senanque.messaging.springintegration.MessageSenderImpl">
    <property name="channel" ref="orderChannel" />
    <property name="replyChannel" ref="orderReplyChannel" />
</bean>
				]]></code>
			<p>...which looks too simple to be true, but it refers to channels in the Spring Integration configuration which is out of scope
			for this document. However it is worth noting that the workflow process definition is only loosely coupled to SI. The workflow
			definition is only vaguely aware of how the messages are handled, it just knows they get sent somehow and a response of some kind comes
			back, and then it can go on.</p>
			<img width="12cm" href="images/LaunchForm.png">LaunchForm</img>
			<p>By the time you see this form the process instance has not yet been launched. If you hit the Cancel button it never will be and there
			is nothing to clean up. Enter 'Order#1' into the Order Name field, accept the default value for Fahrenheit, and click Okay.</p>
			<p>The process instance is launched and its id is displayed, you also have an opportunity to attach documents to the
			process instance at this point.</p>
			<img width="12cm" href="images/LaunchWizard2.png">LaunchWizard2</img>
			<p>And the Okay button will return you to the home page.</p>
			<img width="12cm" href="images/Home2.png">Home-2</img>
			<p>The home page has an entry, which is the process instance you just launched. You won't initially have a queue name, so give it about 30 seconds and click
			refresh until it does. Notice that the Reference column contains 'Order#1' which is what you typed on the launch form. You can also see that it is
			in queue Q1 (when it appears) and that it is running process definition Demo, the definition you launched. This is what you should see
			when the queue is there:</p>
			<img width="12cm" href="images/Home2a.png">Home-2a</img>
			<p>Meanwhile if you look at the application server log you should see something like this:</p>
			<img width="12cm" href="images/log-1.png">log-1</img>
			<p>That shows a web service message being sent and a reply received and unpacked. We have converted 20F to -6.67C. These debug
			logging settings ought to be turned off for production, of course. There is a <courier>logback.xml</courier> file in the usual
			place that controls this.</p>
			<p>The process instance we launched now has a queue name and is in a WAIT state. That means it is waiting for a human to do something. Click on that process instance.</p>
			<img width="12cm" href="images/P1A.png">Process1-Form</img>
			<p>This is the form associated with this stage of the process. It is displaying information about the object associated with this process instance,
			in this case an Order object. It is showing the converted temperature in Celsius. You can click Okay for it to go on to the next step, but before you do click on the
			Process tab.</p>
			<img width="12cm" href="images/P1B.png">Process1-Process</img>
			<p>The Process tab shows the internal details of the process instance. You can see what bundle this process was loaded from, its current status (Busy because you have got it locked)
			what queue it is in and so on. You can view these details but unless you have TECHSUPPORT permission you cannot change them. TECHSUPPORT can change anything
			you see here. There is also an opportunity to view the attachments. Now press the Audit tab.</p>
			<img width="12cm" href="images/P1C.png">Process1-Audits</img>
			<p>The Audit tab shows all the audit records generated for this process instance. You can see what tasks were run and when, and you can see who locked the process instance
			as well. Notice that entries 3 and 4 refer to a process instance of <courier>Demo_1</courier> rather than <courier>Demo</courier>. This is indicates there was an inner
			process generated from the main process' try/catch block. You can click on these entries for more detail.</p>
			<img width="12cm" href="images/P1D.png">Process1-Audits Detail</img>
			<p>Unlike the process instance details no one can edit an audit record, not even someone with TECHSUPPORT permission, although anyone
			with enough access to the database could modify this information, of course.</p>
			<p>Now go back to the Form tab and press Okay. You might need to wait a few seconds and then press refresh to see the process instance
			finished.</p>
			<img width="12cm" href="images/Home3.png">Home-3</img>
			<p>As a demo this perhaps looks a little trivial. But note what happened carefully. A process instance was launched with a launch form which accepted some
			initial data. That process was then managed through multiple stages, including sending a message, operating a form, and optionally running a custom
			compute bean.</p>
			<p>What we did not see yet is handling of errors. Let's go around again, but this time turn off your internet connection and call it
			Order#2. Again give it about 30 seconds to progress through the steps and refresh.</p>
			<img width="12cm" href="images/Home4.png">Home-4</img>
			<p>The new process is id 2. Notice the error message, that is
			because it could not get to the web service. So what happened then? Well, take a look at the process definition again:</p>
				<code><![CDATA[
process: Order "Demo" "This is the demo process" launchForm=LaunchDemo  queue="Q1"{
	try {
		message=orderMessageSender;
	}
	catch (abort) {
		compute=temperatureCompute;
	}
	form=DisplayFahrenheit queue="Q1";
}  
				]]></code>
			<p>If there is an error in the message the catch block will be executed and the compute task will figure out the temperature. It will still
			land on the form, and that is where it is now. If you click on the entry you will see the form.</p>
			<img width="12cm" href="images/P2A.png">Process2-Form</img>
			<p>Click on the process tab.</p>
			<img width="12cm" href="images/P2B.png">Process2-Process</img>
			<p>Now you can see the details of the process, including the error. On the Audit tab you can see the trace of how the error was handled.</p>
			<img width="12cm" href="images/P2C.png">Process2-Audit</img>
			<p>This shows the error from the message and the fact that the compute task was executed. Naturally the form on the first tab looks much the same
			with a computed value for the temperature instead of one fetched from the web.</p>
			<p>So you have now seen how a process can work through a sequence of steps that might include a web service call, a manual form and a compute task.
			The process can handle errors an process them in much the same way Java handles exceptions. Do remember that when we say 'web service'
			we really mean something handled by the external bus, inthis case Spring Integration. Such busses can support many kinds of communication
			and web services are just one example.</p>
			<p>The subject of attachments came up twice in that demo, once when the process was launched and once again when
			operating a form. Attachments are documents of any kind attached to the process instance. There are limitations
			on the size of the document you can attach which vary depending on the database product chosen. But any type of file
			can be attached. Also, attachments are used only for user reference. They do not directly influence the state of the
			process, though a user might make a decision based in information obtained by reading an attachment.</p>
			<p>When the attachment button is pressed you see a window like this:</p>
			<img width="12cm" href="images/Attachments1.png">Attachments-1</img>
			<p>This is the initial view of the attachments on a process instance, before any have been added. Now press the New
			button.</p>
			<img width="12cm" href="images/Attachments2.png">Attachments-2</img>
			<p>It wants a new attachment now. There is space for a comment, a protected flag and the usual buttons to select
			and upload the file. The protected flag means only ADMIN and TECHSUPPORT users can see this attachment. Once
			an attachment is uploaded it goes back to the list of attachments.</p>
			<img width="12cm" href="images/Attachments3.png">Attachments-3</img>
			<p>Now the attachment just added is visible in the table. To examine it you just click on it and the browser will
			attempt to download it or open it, depending on your browser setting. There is no way to remove or modify attachments,
			that allows them to be used as a kind of audit trail.</p>
			</h1>
			
		<h1 t="The UI">
			<h2 t="Vaadin and Madura Vaadin Support">
			<p>There seem to be endless ways of implementing a UI in Java so eventually you just have to pick one you like. In this application the choice
			is Vaadin<referenceLink t="Vaadin"/> mostly because of its Swing-like API and the fact that as far as the programmer is concerned it is Java all the
			way down, you don't have to cope with Javascript or JSP etc. It also has a rich set of controls and all the styling is controlled by CSS. The CSS
			control and the 'Java all the way down' are not contradictory. Programmers should not need to worry very much about styling, that can be turned
			over to a <emph>designer</emph> and they often know CSS better than a Java programmer. Typically programmers can do a rough cut of the application styling and get
			the functionality in place, then get the designer to got to work on the CSS.</p>
			<p>It is no coincidence that Madura Vaadin Support<referenceLink t="Madura Vaadin Support"/> handles the integration between Vaadin and Madura Objects<referenceLink t="Madura Objects"/>.
			That provides dynamic validation on the forms and good I18n support.</p>
			<p>So the choice here is Vaadin with a little help from Madura Vaadin Support.</p>
			</h2>
			<h2 t="Security">
			<p>Security is implemented using Madura Login<referenceLink t="Madura Login"/>, the login filter/interceptor used in the Madura Vaadin Support demos.
			That, by default, uses a simple hard coded list of users an permissions, and the permissions for the logged in user are passed to
			the <courier>PermissionManager</courier> so that all the forms etc honour the permissions for this user.</p>
			<p>In an enterprise environment, and typically workflow would run in an enterprise environment, there is often an external login procedure which adds a security
			token to the request. Madura Vaadin Support's login form supports this, allowing a pre-logged-in user to bypass the login form.</p>
			<p>Queues also have permissions attached to them. That means that users have limited access to view or operate that queue, depending on their permission.
			If the current user has only read access to the queue then items in the queue cannot be opened. If they have no read access to the queue then
			no items from that queue will be displayed.</p>
			<p>There is also one 'super permission' called TECHSUPPORT. Users with this permission can always modify any process instance in any queue, including
			ones that are being worked on by another user. Naturally that capability ought to be used sparingly. The ADMIN permission allows users to view, but
			not necessarily change, anything. The specific names associated with these permissions are defined in the file <courier>FixedPermissions.java</courier> so they
			can be customised where necessary.</p>
			</h2>
			<h2 t="Spring Framework">
			<p>As with other applications that use Madura Vaadin Support, which depends on the Vaadin-Spring Addon<referenceLink t="Vaadin-Spring Addon"/>, we have
			some generic beans defined in the <courier>application-context.xml</courier>, others defined in a <courier>@Configuration</courier> class and the rest
			defined using Spring's ability to scan packages looking for <courier>@Component</courier> annotations. The objective here is to simplify the configuration
			such that as much as possible happens automatically so, in general, you don't need to follow up and understand all the <courier>@Component</courier> and <courier>@Configuration</courier> annotations
			unless you really like that sort of thing. To configure this to your production requirements you will need to adjust <courier>application-context.xml</courier>
			which you will find in the <courier>WEB-INF</courier> directory. There are several references to the <courier>application-context.xml</courier> in the following
			sections.</p>
			</h2>
			<h2 t="Scheduler">
			<p>The scheduler is configured using Spring in <courier>applicationContext.xml</courier> like this:</p>
        <code><![CDATA[
<!-- The executor is responsible for scanning for active processes etc -->
<bean id="executor" class="nz.co.senanque.workflow.ExecutorImpl" />

<task:scheduler id="myScheduler" pool-size="10" />
<task:scheduled-tasks scheduler="myScheduler">
    <task:scheduled ref="bundleManager" method="scan"
        fixed-delay="10000" />
</task:scheduled-tasks>
<task:scheduled-tasks scheduler="myScheduler">
    <task:scheduled ref="executor" method="activeProcesses"
        fixed-delay="10000" />
</task:scheduled-tasks>
<task:scheduled-tasks scheduler="myScheduler">
    <task:scheduled ref="executor" method="deferredEvents"
        fixed-delay="10000" />
</task:scheduled-tasks>
<task:scheduled-tasks scheduler="myScheduler">
    <task:scheduled ref="executor" method="clearDeferredEvents"
        fixed-delay="60000" />
</task:scheduled-tasks>
        ]]></code>
        	<p>The key to this is the <courier>myScheduler</courier> to which are added several tasks. The first is the task that
        	invoked the bundle manager to scan the bundles directory for new bundles. The other three are workflow tasks and they
        	invoke different methods on the <courier>executor</courier> bean.</p>
        	<p>The first of these scans for active processes, ie processes in tasks that can be executed off line. Such tasks include
        	compute tasks and message tasks, but they do not include form tasks which need user input.</p>
        	<p>The other two tasks are for handling deferred events, which mostly means timeouts. When a deferred even comes due the
        	relevant process instance has its status updated and then left for the active process handler to progress it. The <courier>clearDeferredEvents</courier>
        	method is minor housekeeping which organises removing old deferred events. It does not need to run as often as the others.</p>
        	<p>If you need to deploy multiple copies of the application all using the same databases then depending on your workload profile
        	you could consider having the workflow scheduled tasks run in only one of those copies because doing all the off-line processing
        	from one dedicated machine is often a good idea. But multiple copies will run happily enough together.</p>
        	<p>But all copies of the application must scan the bundles directory because they must all be aware of the same bundles.</p>
			</h2>
		</h1>
		<h1 t="Workflow Bundles">
			<p>By making use of Madura Bundles<referenceLink t="Madura Bundles"/> the application supports deploying of new workflow definitions and their associated
			resources on the fly. A bundle is a specially packaged jar file and by copying a new jar file into the monitored directory a new bundle can be
			deployed or an existing bundle can be upgraded<footnote>Since Madura Bundle 4.0.0 bundles may be deployed to a maven repository
			and, instead of copying the jar file to the monitored directory you copy a small text file describing the bundle instead.</footnote>. In the case of new bundles the workflow definitions contained in the bundle will become visible on
			the list of launchable processes in the UI. For upgraded bundles the situation is more complex because there may be active process instances using
			the previous version (say, version 0.0.1) and now we have 0.0.2. Those active process instances will actually continue to use the workflow definition they started with,
			and only new launches will use the 0.0.2 version.</p>
			<p>Bundles, as already noted, are just specially packaged jar files, which means they have some extra entries in the <courier>MANIFEST.MF</courier> file, including
			a reference to a Spring context file. So they are just ordinary Madura Bundles, and we will work through their configuration in detail below. First
			we need to look at the bundle configuration in the main application.</p>
			<h2 t="Bundle Configuration">
        <code><![CDATA[
<bean id="bundleManager" class="nz.co.senanque.madura.bundle.BundleManagerImpl">
  <property name="directory" value="${workflow.bundles.dir}"/>
    <property name="exportedBeans">
      <map>
        <entry key="errorEndpoint" value-ref="errorEndpoint"/>
        <entry key="genericEndpoint" value-ref="genericEndpoint"/> 
      </map>
    </property>
</bean>
        ]]></code>
        <p>This is from the <courier>application-context.xml</courier> file. It uses an external variable which holds the location of the directory the bundles
        are held in. This directory will be scanned every few (configurable) seconds for new files. You should configure this </p>
        <p>Notice that we explicitly export the two endpoint beans. Most of the time we can annotate the beans
        for export and leave this list empty but these two beans have the bundle proxy <courier>workflowManager</courier>
        injected into them. Spring gets confused when handling that case but explicitly adding them to the list works just fine.</p>
        <p>Now, inside a bundle we always have a bean defining the workflow manager from the config.properties file which contains something this:</p>
        <code><![CDATA[
nz.co.senanque.workflow.WorkflowManager.schema=classpath:/OrderInstances.xsd
nz.co.senanque.workflow.WorkflowManager.processes=classpath:/OrderWorkflow.wrk
        ]]></code>
        <p>This refers to the xsd file that defines the objects used by the workflow, and the wrk file that contains the workflow process definitions.
        The workflow manager bean itself is a component defined via the scanner.</p>
        <p>As well as this the bundle needs a JPA database, yes another one, see <sectionLink t="Database"/> for details as to why.</p>
        <p>All the beans defined in the bundle context file are singletons unless scoped otherwise, and one or two are. Here are the
        rest of the essential beans:</p>
        <code><![CDATA[
<import resource="classpath:/database-orderinstances-context.xml"/>
<import resource="classpath:/SI-context.xml"/>

<context:annotation-config />
<context:component-scan base-package="nz.co.senanque.validationengine,nz.co.senanque.rules,
		nz.co.senanque.vaadin,nz.co.senanque.workflow.conf,nz.co.senanque.workflow.order,
		nz.co.senanque.workflow.orderrules" />
<context:property-placeholder location="classpath:/config.properties" />

<!-- 
message sender(s) and compute(s) used by the processes
This is the Spring Integration message sender. Other messages busses need a different class here.  
-->
<bean id="orderMessageSender" class="nz.co.senanque.messaging.springintegration.MessageSenderImpl">
    <property name="channel" ref="orderChannel" />
    <property name="replyChannel" ref="orderReplyChannel" />
</bean>

<bean id="messageSource" class="nz.co.senanque.resourceloader.ResourceBundleMessageSourceExt">
    <property name="basenames">
        <list>
            <value>localmessages</value>
        </list>
    </property>
</bean>
        ]]></code>
		<p>This file imports a database configuration which will be discussed in detail in <sectionLink t="Database"/>. Most of the configuration is automated by using
		the right scan list and property placeholder. This workflow bundle needs the rules engine, but if you are not using rules that can
		be left out. It also uses messaging and delegates that to Spring Integration, hence the import of <courier>SI-context.xml</courier>
		and the <courier>orderMessageSender</courier> bean.</p>
		<p>The <courier>orderMessageSender</courier> bean injects two Spring Integration Channels into the <courier>nz.co.senanque.messaging.springintegration.MessageSenderImpl</courier> class.
		This is the only dependency on Spring Integration. To use a different message bus you would supply your own implementation of 
		<courier>nz.co.senanque.messaging.springintegration.MessageSender</courier> and configure as needed.</p>
		<p>Finally we should include a <courier>messageSource</courier> bean to load the relevant resource bundles.</p>
		</h2>
		<h2 t="Bundled Forms">
		<p>If the workflow definition includes <courier>form</courier> tasks or launch forms then those forms
		must be in the bundle, they cannot be delivered by the main application because it does not know
		anything about the data in the workflow definition. That means the forms are configured in the
		bundle like this:</p>
        <code><![CDATA[
<bean id="VaadinLaunchForm" class="nz.co.senanque.workflow.VaadinLaunchForm" scope="prototype">
	<property name="referenceName" value="orderName"/>
</bean>
<bean id="VaadinFirstForm" class="nz.co.senanque.workflow.VaadinFirstForm" scope="prototype">
	<property name="fieldList">
		<list>
			<value>orderName</value>
			<value>celsius</value>
		</list>
	</property>
</bean>  
        ]]></code>
		<p>The two forms are referred to by the workflow definition. It has an entry like this:</p>
        <code><![CDATA[
...
process: Order "Process2" "This is the second process" launchForm=LaunchForm {
	try {
		message=orderMessageSender;
		form=FirstForm queue="Q1";
...
        ]]></code>
		<p>There they are! LaunchForm and FirstForm. The name of the form in the definition is just the
		name of the bean in the bundle... except the beans have 'Vaadin' on the front of it so them is
		a little more complicated. The forms are actually delivered using the <courier>formFactory</courier>
		bean in the main application and that is auto-injected with the <courier>formEnvironment</courier> bean which contains
		the string 'Vaadin' by default. The value can be overidden by adding an entry for <courier>nz.co.senanque.forms.FormEnvironment.name</courier>
		to <courier>config.properties</courier>. Remember these beans are all in the <emph>application</emph> context. The workflow
		bundles all use those application level beans to know about their environment.</p>
		<p>Why would you ever need that extra complication? Well sometimes you might have multiple UI technologies going on at once.
		Some users, perhaps, are using Vaadin and others for whatever reason are using Swing and others are using Camel. You only need
		to ensure the <courier>formEnvironment</courier>bean for each user has the right value and then you would define <emph>six</emph> beans 
		to cover all the cases like this:</p>
        <code><![CDATA[
...
<bean id="VaadinLaunchForm" class="nz.co.senanque.workflow.VaadinLaunchForm" scope="prototype">
	<property name="referenceName" value="orderName"/>
</bean>
<bean id="VaadinFirstForm" class="nz.co.senanque.workflow.VaadinFirstForm" scope="prototype">
	<property name="fieldList">
		<list>
			<value>orderName</value>
			<value>celsius</value>
		</list>
	</property>
</bean>
<bean id="SwingLaunchForm" class="nz.co.senanque.workflow.SwingLaunchForm" scope="prototype">
	<property name="referenceName" value="orderName"/>
</bean>
<bean id="SwingFirstForm" class="nz.co.senanque.workflow.SwingFirstForm" scope="prototype">
	<property name="fieldList">
		<list>
			<value>orderName</value>
			<value>celsius</value>
		</list>
	</property>
</bean>
<bean id="CamelLaunchForm" class="nz.co.senanque.workflow.CamelLaunchForm" scope="prototype">
	<property name="referenceName" value="orderName"/>
</bean>
<bean id="CamelFirstForm" class="nz.co.senanque.workflow.CamelFirstForm" scope="prototype">
	<property name="fieldList">
		<list>
			<value>orderName</value>
			<value>celsius</value>
		</list>
	</property>
</bean>   
        ]]></code>
		<p>With that in place the right form will be delivered to the right user. However, so far only Vaadin forms have been fully implemented so if you do
		want Swing or Camel you will have more work to do than for Vaadin. It is probably fairly easy to build a simple form in another technology (depending
		on the technology, of course), more complex is integrating that form with Madura Objects. Without Madura Objects the forms would need to be more
		complicated and harder to maintain.</p>
		<p>In practice the two Vaadin forms in the sample are very simple extensions of a base class <courier>GenericVaadinForm</courier> that is packaged in the
		main application. The base class is generic enough to simply generate a form based on the object it is bound to using all the properties it finds in it,
		unless a field list is supplied (as it is with the FirstForm) in which case just those fields are displayed. It also presents three buttons: OK, Cancel
		and Park. The first two are obvious enough but the last allows a user to save the current process instance without actually releasing it, useful if they
		have not completed it but want to go home for the night etc.</p>
		<p>The generic form also has a <courier>referenceName</courier> property. When the form is saved the property named for this (<courier>orderName</courier>)
		in this case, is copied to the process instance reference, which means it is visible in the table of process instances.</p>
		<p><courier>GenericVaadinForm</courier> is smart enough to generate date fields from date properties, checkboxes from booleans, drop downs from
		enums etc and because they are backed by Madura Objects you get automatic validation of the fields. For example numeric fields will insist the user
		enters a number. Labels are automatically generated and they are all supported by I18n. Even better you can use Madura Rules to add
		rules for cross field validation and to make the forms dynamic. For example you can specify rules that will limit the drop down lists
		on one field depending on values entered into other fields, you can also add rules that switch fields from enabled to disabled, visible and
		invisible etc.</p>
		<p>While you can use rules to control if fields are readOnly or not, you sometimes want to make a whole form readOnly. You can do that with the
		readOnlyForm property like this:</p>
		<code><![CDATA[
<bean id="VaadinFirstForm" class="nz.co.senanque.workflow.VaadinFirstForm" scope="prototype">
	<property name="readOnlyForm" value="true"/>
	<property name="fieldList">
		<list>
			<value>orderName</value>
			<value>celsius</value>
		</list>
	</property>
</bean>
		]]></code>
		<p>So you can get quite a long way with just using <courier>GenericVaadinForm</courier>. But in a production application you would
		eventually need to add something else. For example if you have an Order which needs OrderItems added you would probably extend <courier>GenericVaadinForm</courier>
		but you would add more code to it to create OrderItems, attach them to the Order and so on. There would likely be more buttons
		involved and at least one popup window. But do remember than the OrderItems can be monitored by rules as well. So, for example, to
		get the order total you would write a rule and the total would be updated as OrderItems are added, deleted or their details changed.</p>
		</h2>
		<h2 t="Bundle contents">
		<p>There are three working bundles supplied with the application: nmc-workflow, order-workflow and simple-workflow, the most interesting one is order-workflow.
		They are all maven projects under the <courier>madura-workflow</courier> directory. The resulting jar files are copied to <courier>madura-workflow-impl/bundles</courier> directory
		as well so this is where <courier>bundlesDir</courier> ought to point to.</p>
		<p>The order-workflow bundle looks like this:</p>
		<img width="12cm" href="images/Workflow1Contents.gif">order-workflow Bundle</img>
		<p>There are two subdirectories at the top, the <courier>nz</courier> is the beginning of the <courier>nz.co.senanque.workflow</courier>
		structure which is detailed later. <courier>META-INF</courier>, as usual, contains the <courier>MANIFEST.MF</courier> file which
		in this case looks like this:</p>
        <code><![CDATA[
Manifest-Version: 1.0
Implementation-Title: Order Workflow
Implementation-Version: 1.0.2
Built-By: roger
Bundle-Name: order-workflow
Created-By: Apache Maven 3.2.1
Implementation-Vendor: Prometheus Consulting
Implementation-Vendor-Id: nz.co.senanque
Bundle-Version: 1.0.2
Build-Jdk: 1.7.0_67
Bundle-Context: order-workflow-context.xml
Bundle-Activator: nz.co.senanque.madura.bundle.BundleRootImpl
Bundle-Description: A sample bundle containing a workflow.
        ]]></code>
        <p>This is normal for a Madura Bundle and the main thing to note is that the <courier>Bundle-Context</courier> specifies the
        <courier>workflow-context.xml</courier>, which is the Spring context that is to be loaded for this bundle.</p>
        <p>After the subdirectories there are a number of files in the top directory of the jar file.</p>
        <p><courier>order-workflow-context.xml ,SI-context.xml</courier> and <courier>database-orderinstances-context.xml</courier> are all
        Spring context files. <courier>order-workflow-context.xml</courier> is the main one that imports the other two. 
        <courier>database-orderinstances-context.xml</courier> contains the database definitions and <courier>SI-context.xml</courier>
        contains Spring Integration configuration, which means this bundle uses SI to send messages to external services, typically
        web services.</p>
        <p><courier>OrderWorkflow.wrk</courier> and <courier>OrderInstances.xsd</courier> are the process definitions and the definitions
        of the objects they refer to. The xsd file has already been used to generate the annotated POJOs but it has a runtime
        function as well.</p>
        <p>There are two xsl files which are used to generate and unpack web services messages. These are referred to by <courier>SI-context.xml</courier>,
        and there are several properties files used to provide I18n translation.</p>
        <p>Finally the <courier>OrderRules.rul</courier> file contains the Madura Rules that monitor the objects defined in the xsd
        file. This file actually has no runtime function because the rules have been generated into Java classes and placed in 
        <courier>nz.co.senanque.workflow.orderinstances</courier>. <courier>choices.xml</courier> and <courier>Messages.xml</courier> are also used by Madura Rules.</p>
        <p>Which brings us to the contents of the <courier>nz.co.senanque.workflow</courier> structure.</p>
        <p><courier>nz.co.senanque.workflow.orderinstances</courier> contains the POJOs generated from the xsd file and <courier>nz.co.senanque.workflow.orderrules</courier>
        contains the generated rules. At the top of the structure, ie in <courier>nz.co.senanque.workflow</courier> are classes for the two Vaadin forms
        and the two custom compute classes referred to by the workflow definition.</p>
		</h2>
		</h1>
		<h1 t="Database">
		<p>There is a database for the core workflow tables and a database to hold the data for each bundle. It is important that these databases
		are kept separate because new bundles can be added or removed independently of the core workflow, and independently of each other.
		Transactions across multiple connections have to be coordinated too.</p>
		<p>The default application uses either MySQL or H2 as a database. H2 has the advantage that it can be memory resident and requires
		no installation, which makes it very good for demos, though not so good for production. H2 can also be configured to be non-memory
		resident but it is not often used in production. MySQL is widely accepted as a production database but it requires installation etc.</p>
		<p>To configure the specific options you want you can edit the config.properties file or use environment variables to override the
		config.properties values. All the config.properties are described detail in <referenceLink t="Configuring for Production"/>
		but in general you should assume all your databases are of the same type and on the same server, though each has a different name.
		For example if you decide to use MySQL on your localhost then your workflow database and each bundle database will all be
		MySQL on localhost. You can customise each database to be in a different location if you want but it makes it more difficult to maintain.</p>
		<p>What follows are technical details of the database configuration. These have been put into XML to make them more visible in case
		you need to change them. In practice you should not need to change the core database definitions, but you might. When you build
		a bundle of your own you will want to clone one of the example configurations so that is described in detail.</p>
		<p>An important option to note is whether you want the database tables etc to be created automatically on first access. This makes
		sense when using memory resident H2 in a demo, but often you want to fine tune the database structure in production, in which
		case you want to modify the relevant config.properties setting.</p>

		<h2 t="Workflow Database">
		<p>Now it is time to look at the workflow database configuration (as opposed to the one in the bundle). This is
		the <courier>database-context.xml</courier> file:</p>
        <code><![CDATA[
...
	<bean id="em-workflow"
		class="org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean" depends-on="springJtaPlatformAdapter" bundle:export="true">
		<property name="persistenceXmlLocation" value="classpath:META-INF/persistence-workflow.xml" />
		<property name="persistenceUnitName" value="pu-workflow" />
		<property name="dataSource" ref="dataSourceWorkflow" />
		<property name="jpaVendorAdapter" ref="jpaVendorAdapter" />
		<property name="jpaDialect">
			<bean class="org.springframework.orm.jpa.vendor.HibernateJpaDialect" />
		</property>
		<property name="jpaProperties">
			<map>
				<entry key="hibernate.transaction.jta.platform" value="nz.co.senanque.hibernate.SpringJtaPlatformAdapter" />
				<entry key="hibernate.dialect" value="${database.dialect}" />
				<entry key="hibernate.format_sql" value="true" />
				<entry key="hibernate.connection.autocommit" value="false" />
			</map>
		</property>
	</bean>

	<bean id="databaseConfigurer" class="nz.co.senanque.workflowimpl.DatabaseConfigurer" bundle:export="true">
		<property name="extraProperties">
			<util:properties location="classpath:xa-${database.type}.properties"/>
		</property>
	</bean>
	
    <bean id="dataSourceWorkflow" class="com.atomikos.jdbc.AtomikosDataSourceBean" init-method="init" destroy-method="close">
	    <property name="uniqueResourceName" value="pu__workflow" />
	    <property name="xaDataSourceClassName" value="#{databaseConfigurer.datasourceClass}" />
	    <property name="xaProperties" value="#{databaseConfigurer.properties('workflow')}"/>
	    <property name="maxPoolSize" value="#{databaseConfigurer.maxPoolSize}"/>
	    <property name="minPoolSize" value="#{databaseConfigurer.minPoolSize}"/>
	    <property name="borrowConnectionTimeout" value="#{databaseConfigurer.borrowConnectionTimeout}" />
	</bean>

	<bean id="jpaVendorAdapter"
		class="org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter" bundle:export="true">
		<property name="showSql" value="false" />
		<!-- ensures new db is auto created if needed -->
		<property name="generateDdl" value="${database.generateDdl}" />
		<property name="databasePlatform" value="#{databaseConfigurer.dialect}" />
	</bean>

    <bean id="springJtaPlatformAdapter" class="nz.co.senanque.hibernate.SpringJtaPlatformAdapter">
        <property name="jtaTransactionManager" ref="transactionManager" />
    </bean>
    <bean id="atomikosTransactionManager" class="com.atomikos.icatch.jta.UserTransactionManager"
		init-method="init" destroy-method="close" bundle:export="true">
		<property name="forceShutdown" value="false" />
	</bean>
    <bean id="atomikosUserTransaction" class="com.atomikos.icatch.jta.UserTransactionImp" bundle:export="true">
        <property name="transactionTimeout" value="${database.transaction.timeout}" />
    </bean>
	<bean id="transactionManager"
		class="org.springframework.transaction.jta.JtaTransactionManager" bundle:export="true">
		<property name="transactionManager" ref="atomikosTransactionManager" />
		<property name="userTransaction" ref="atomikosUserTransaction" />
		<property name="allowCustomIsolationLevels" value="true" />
	</bean>
	
    <bean id="persistenceAnnotation" class="org.springframework.orm.jpa.support.PersistenceAnnotationBeanPostProcessor" />
        ]]></code>
        <p><courier>em-workflow</courier> is the JPA entity manager for the core workflow
        database. This specifes the persistence xml file and a unit name. It also specifies
        that this entity manager uses Hibernate and the selected dialect, as well as a datasource
        called <courier>datasourceWorkflow</courier>.</p>
        <p>The <courier>databaseConfigurer</courier> bean is used to construct a properties list for the data source. If
        we were just configuring one data source this bean would be overkill but we want to pass a similar list to
        the bundles and keep their configuration needs as simple as possible. The bean is injected with values from
        <courier>config.properties</courier>, all of which can be overidden by environment variables (eg the <courier>-D</courier> flag on the command line).
        The values specify the connection url and the user, password etc. The url is specified as a prefix and a suffix so
        that you can specify a particular schema in the target database. For example the main workflow database
        is <courier>workflow</courier> and in <courier>config.properties</courier> we have:</p>
        <code><![CDATA[
...
#database.url.prefix=jdbc:h2:mem:
#database.url.suffix=;DB_CLOSE_ON_EXIT=FALSE;MVCC=true
...
        ]]></code>
        <p>When the <courier>databaseConfigurer</courier> bean supplies the list of properties it accepts an argument which
        names the specific schema so that it can construct the url correctly. </p>
        <p><courier>datasourceWorkflow</courier> is the Atomikos wrapper for the
        selected JDBC datasource and it specifies the url for the database location. It also specifes 
        a unique resource name which is used by the transaction manager. In this file there is a reference in
        the <courier>dataSourceWorkflow</courier> bean that looks like this:</p>
        <code><![CDATA[        
<property name="xaProperties" value="#{databaseConfigurer.properties('workflow')}"/>
        ]]></code>
		<p>That results in the full list of properties, including the url which looks like this:</p>
        <code><![CDATA[        
jdbc:h2:mem:workflow;DB_CLOSE_ON_EXIT=FALSE;MVCC=true
        ]]></code>
        <p>As you can see the url is constructed from the specified prefix, schema ('workflow'), and suffix. The other properties
        such as user and password are passed without alteration. The only other thing to notice about this bean is that it
        is injected with a list of extra properties which depend on the the <courier>database.type</courier> value in the <courier>config.properties</courier> file.
        It looks for a properties file called, for example <courier>xa-H2.properties</courier> or <courier>xa.MySQL.properties</courier> in the top of the classpath. 
        The H2 file can be empty but the MySQL file needs to have <courier>pinGlobalTxToPhysicalConnection=true</courier>. Those are the two database platforms
        that have been tested, other platforms would need their own xa file.</p>
        <p>The <courier>databaseConfigurer</courier> bean also carries other injected values such as the data source class and the pool size limits.
        You can see these being used in the <courier>dataSourceWorkflow</courier> bean.</p>
        <p>As noted above, this is more complicated than it needs to be for just one database connection which is all we need in the main application.
        But notice that the <courier>databaseConfigurer</courier> bean is exported to the bundles, meaning they can pick up the same bean (and its contents)
        to specify their own database connections.</p>
		<p><courier>jpaVendorAdapter</courier> specifies some Hibernate switches, this is also exported to the bundles.
		The database configuration included assumes the databases will be created when the connection
		is requested, depending on the value of <courier>database.generateDdl</courier>. In production you would more 
		likely have SQL scripts to do this and you would run them beforehand.</p>
		<p>The rest of the beans are all relating to transaction management. They ensure
		that the Atomikos transaction manager is configured properly with Spring, including annotation
		driven transactions.</p>
		</h2>
		<h2 t="Bundled Databases">
		<p>Meanwhile the bundles define their own database connections and it is vital that
		both databases are kept in sync, which is why we need the 2 phase commit support that
		Atomikos provides. Remember there might be multiple bundles, and each bundle might define a different
		database. The configuration in the bundle should look like this:</p>
        <code><![CDATA[
...
	<bean id="em-local"
		class="org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean">
		<property name="persistenceXmlLocation" value="classpath:/META-INF/persistence-orderinstances.xml" />
		<property name="persistenceUnitName" value="pu-orderinstances" />
		<property name="dataSource" ref="dataSourceLocal" />
		<property name="jpaVendorAdapter" ref="jpaVendorAdapter" />
		<property name="jpaDialect">
			<bean class="org.springframework.orm.jpa.vendor.HibernateJpaDialect" />
		</property>
		<property name="jpaProperties">
			<map>
				<entry key="hibernate.transaction.jta.platform" value="nz.co.senanque.hibernate.SpringJtaPlatformAdapter" />
				<entry key="hibernate.dialect" value="#{databaseConfigurer.dialect}" />
				<entry key="hibernate.format_sql" value="true" />
				<entry key="hibernate.connection.autocommit" value="false" />
			</map>
		</property>
	</bean>

    <bean id="dataSourceLocal" class="com.atomikos.jdbc.AtomikosDataSourceBean" init-method="init" destroy-method="close">
	    <property name="uniqueResourceName" value="${bundle.name}" />
	    <property name="xaDataSourceClassName" value="#{databaseConfigurer.datasourceClass}" />
	    <property name="xaProperties" value="#{databaseConfigurer.properties('orders')}"/>
	    <property name="maxPoolSize" value="#{databaseConfigurer.maxPoolSize}"/>
	    <property name="minPoolSize" value="#{databaseConfigurer.minPoolSize}"/>
	    <property name="borrowConnectionTimeout" value="#{databaseConfigurer.borrowConnectionTimeout}" />
	</bean>
...
        ]]></code>
        <p>This is simpler than the main application configuration because many of the beans are
        already defined there and shared with this configuration. So all we need here is an
        entity manager and a data source, and they look much like the ones we already saw.</p>
        <p>The one key difference is the unique resource name, which is here set to <courier>${bundle.name}</courier>.
        This is the name of the bundle plus its version, so if you upgrade a bundle this unique
        name will still be unique, and it needs to be. The <courier>${bundle.name}</courier> is always
        set by the bundle manager so you don't have to do anything to set it.</p>
        <p>It is worth noting that the <courier>persistenceXmlLocation</courier> refers to a file contained in the
        bundle and that, in turn, refers to annotated POJOs also contained in the bundle. Also that the reference
        to the <courier>jpaVendorAdapter</courier> and <courier>databaseConfigurer</courier> beans are actually a 
        reference to a bean in the main application that is passed to the bundle. In the case of the <courier>databaseConfigurer</courier>
        bean we pass a schema name when we get the xaProperties value:</p>
        <code><![CDATA[
<property name="xaProperties" value="#{databaseConfigurer.properties('orders')}"/>
        ]]></code>
        <p>This will create the full properties list using the values in the bean, but the url will be formed from the specified
        prefix+schema+suffix to get the specific url for the database used by this bundle.</p>
        </h2>
		</h1>
	<h1 t="Locking">
		<p>While it is common to rely on database for locking the workflow often needs to lock things across transactions so it uses
		the locking facility from Madura Utils<referenceLink t="Madura Utils"/>. This has two variants, and it is easy to add more.</p>
		<p>For this demo the choice is <courier>SQLLocking</courier> which uses its own database connection to store the flags on a database table. 
		See the Madura Utils documentation for how to configure that.
		You may also want to develop your own locking mechanism and Madura Utils has documentation for that too.</p>	
	</h1>
	<h1 t="JMX">
		<p>The application supports JMX which allows you to monitor it and perform some maintenance operations remotely. This feature
		is completely optional so you can ignore this section if you do not want to use JMX.</p>
		<p>For Tomcat you need to set up some environmental variables to start the MBean server:</p>
        <code><![CDATA[
-Dcom.sun.management.jmxremote
-Dcom.sun.management.jmxremote.port=1099
-Dcom.sun.management.jmxremote.local.only=false 
-Dcom.sun.management.jmxremote.authenticate=false
-Dcom.sun.management.jmxremote.ssl=false
        ]]></code>
        <p>This is a minimal list and your specific requirements may be different, especially in production where turning off authentication is unlikely
        to be a good idea. Also if you are not using Tomcat your requirements may be different. The important thing is to ensure that
        you have an MBean server. There are several JMX clients available and the example shown here uses jconsole which is
        distributed with the HotSpot JVM. When you invoke it you need to give an IP address (127.0.0.1 for the local machine) and
        the port (eg 1099) you configured earlier.</p>
<img width="12cm" href="images/jconsole.png">jconsole</img>
		<p>The relevant entries on the side pane shown in <figureLink t="jconsole"/> are SQLLockFactory, BundleManager and ExecutorJMX.</p>
		<p>The SQLLockFactory entry allows you to change the sleep time, max retries and prefix. You can also get a list of all the locks
		currently held (getAllLocksJMX) and you can force an unlock for a specific lock by name. Unlocking is the same as removing the
		row from the SQL_LOCK table. You should never have to do this, but some unexpected situation might require it.</p>
		<p>The BundleManager entry allows you to get a list of the current bundles (showBundles), force a scan for new bundles and
		restart which removes all bundles and reloads them. Again you should never normally need these. Perhaps if you prefer to turn the
		automatic bundle scanning off you would use it to manually scan when you deployed a new bundle.</p>
		<p>The ExecutorJMX entry allows you to stop and start the background executor. As with the other entries this should not be necessary for normal
		operation but there might be an emergency situation which requires it.</p>
		<p>All of these settings and operations, with the exception of the SQLLockFactory getAllLocks and unlock, apply to a specific server.
		If you have multiple servers running, which is likely enough in production, then the JMX interface is only talking to <emph>one</emph>
		of them and if you need the operation or setting to apply to the others you must connect jconsole to each one of them and
		make your changes there as well. The reason SQLLockFactory is different is that it writes its changes to the lock database
		which is (obviously) visible to all servers.</p>
	</h1>
    <h1 t="Configuring for Production">
    	<p>The configuration options are all in <courier>config.properties</courier> but to change them you do not have to edit
    	the source code. You can override any of them with environment variables.</p>
        <code><![CDATA[
# Do not change settings in this group (unless you want it to break :))
nz.co.senanque.validationengine.ValidationEngineImpl.identifier=my-identifier
nz.co.senanque.validationengine.metadata.AnnotationsMetadataFactory.packages=nz.co.senanque.workflow.instances
nz.co.senanque.forms.FormEnvironment.name=Vaadin

# The following entry will auto login to admin/admin, useful for testing.
#nz.co.senanque.login.RequestValidatorImpl.defaultLogin=admin/admin
# This is the sweep directory that holds the current bundles.
# YOU DEFINITELY NEED TO CHANGE THIS
workflow.bundles.dir=/bundles

# sweep time to check for new bundles
nz.co.senanque.workflowimpl.BundleScheduler.scan=10000

# Sweep times for active processes etc.
# only used if nz.co.senanque.workflowimpl.ScheduleCondition=on
nz.co.senanque.workflowimpl.Scheduler.activeProcesses=10000
nz.co.senanque.workflowimpl.Scheduler.deferredEvents=10000
nz.co.senanque.workflowimpl.Scheduler.clearDeferredEvents=60000
# This turns on the scheduled sweeps for active processes etc
# if this is off the above settings are inactive.
nz.co.senanque.workflowimpl.ScheduleCondition=on

# Use these values for an H2 memory resident database 
database.dialect=org.hibernate.dialect.H2Dialect
database.datasource.class=org.h2.jdbcx.JdbcDataSource
database.url.prefix=jdbc:h2:mem:
database.url.suffix=;DB_CLOSE_ON_EXIT=FALSE;MVCC=true
database.user=
database.password=
database.type=H2

# Use these values for a MySQL database on localhost
#database.datasource.class=com.mysql.jdbc.jdbc2.optional.MysqlXADataSource
#database.url.prefix=jdbc:mysql://localhost:3306/
#database.url.suffix=?autoReconnect=true&useSSL=false
#database.user=workflow
#database.password=workflow
#database.type=MySQL

# THIS HAS TO BE UNIQUE
database.transaction.id=impl
# misc database settings
database.min.pool.size=2
database.max.pool.size=50
database.borrow.connection.timeout=60
database.transaction.timeout=300
database.generateDdl=true
        ]]></code>
		<p>First note that you must change the value for <courier>workflow.bundles.dir</courier> or it will not know
		where to find your bundles.</p>
		<p>The <courier>nz.co.senanque.workflowimpl.BundleScheduler.scan</courier> probably does not need to change. You could make
		it longer if you have performance issues and you do not add new bundles very often. Bundle scans are not resource hungry though.</p>
		<p>The next section covers how often the database is swept for active processes, deferred events and for dead deferred events that need cleaning up.
		These sweeps are more resource intensive so making the time between sweeps might help performance in some circumstances. You can also turn all
		these sweeps off (except the BundleScheduler) using <courier>nz.co.senanque.workflowimpl.ScheduleCondition=off</courier>. This is done when you
		are running multiple workflow servers on the same database and you don't want all of them sweeping.</p>
		<p>The next two sections define the database connections. One of them shows how to define connections to an H2 memory residentdatabase, the other to a
		persistent MySQL database. The application supports either. If you need to add another database choice then you need to change the dependencies and
		rebuild. Using these choices, though, you can see there are two database URL entries: the prefix and the suffix. These are used to surround the
		base name of the database. For example the core workflow database is always called 'workflow' so for MySQL the resulting URL is:
        <code><![CDATA[
jdbc:MySQL://localhost:3306/workflow?autoReconnect=true&useSSL=false
        ]]></code>
		Each bundle has its own unique database name that has a URL
		generated the same way, although you can also customise bundle URLs as you please.</p>
		<p>The last section contains some database tunable values as well as the instruction whether or not to generate the DDL forthe database. If true then
		the database tables will be created when you first connect. This needs to be the case if you are using an in-memory database, but if you are using
		MySQL you have more choice.</p>
		<p>For MySQL you always need to create the all the databases you are going to need as well as a user to access them. For the core application and
		the demo bundles use the MySQL utility to enter these commands:</p>
        <code><![CDATA[
create user 'workflow'@'%' identified by 'workflow';
create database workflow;
create database nmc;
create database simple;
create database orders;
grant all privileges on workflow.* to 'workflow'@'%';
grant all privileges on nmc.* to 'workflow'@'%';
grant all privileges on simple.* to 'workflow'@'%';
grant all privileges on orders.* to 'workflow'@'%';
flush privileges;
        ]]></code>
        <p>With that done you can leave the <courier>database.generateDdl</courier> as true (the default) and the DDL scripts will be generated and run
        when needed. But you may want to tune that DDL. In that case you should use the MySQL utility to run your own DDL and set <courier>database.generateDdl</courier> to false.</p>
		<p>Other changes to consider when moving to production:</p>
		<list>
		<le>Security. The hard coded users in the security configuration must be reworked to use your enterprise security facilities. See the documentation
		for Madura Login<referenceLink t="Madura Login"/> for details.</le>
		<le>Locking. You will need to create the lock table in your workflow database. This is
		documented in Madura Utils<referenceLink t="Madura Utils"/>. By default the locking table is auto-created but your DBA may prefer you use a script.</le>
		<le>The CSS definitions. You do not have to keep the defaults. You can change all the fonts, colours and images and completely rebrand this application if you know enough about CSS 
		and just a little about Vaadin<referenceLink t="Vaadin"/>. The CSS files are in <courier>src/main/webapp/VAADIN/themes/mytheme</courier>.</le>
		<le>Language translations. The application is, we believe, fully i18n compliant. You will want to look at <courier>src/main/resources/messages.properties</courier>
		and produce a translated version of that. There is already a French one there. You also need to check <courier>localmessages.properties</courier> in the bundles.
		If you are using Madura Objects and Madura Rules you may want to translate their message files as well.</le>
		<le>Writing your own workflow definitions, forms, objects and rules. The whole reason for doing this is to get the workflow you really want,
		so this step is obvious. It is where, hopefully, most of the work will go to get the application where you want it.</le>
		</list>
		<p>The default application runs everything in one war file, that means the UI and the background functions are all running in the same
		instance. In production you may want to deploy multiple war files across different servers etc. In that case make sure you set each of them
		to use a different <courier>database.transaction.id</courier> value. It does not matter too much what it contains as long as it is unique.
		This is required by Atomikos to manage the transactions correctly.</p>
		<p>In some cases you might want to separate the UI instances from the back end processing. For this you just need to run the uber jar
		file generated by the headless project. This is configured in the same way as the war file, so you use the same <courier>config.properties</courier> and override
		them with environment variables. You do have to set the <courier>database.transaction.id</courier> to something unique, of course, and you
		probably want to ensure the war deployment(s) are not doing the background handling as well. To turn off the background processing set
		the value of <courier>nz.co.senanque.workflowimpl.ScheduleCondition</courier> to 'off'. Naturally the background processor(s) need the same
		database configuration and bundles directory as the war deployment(s).</p>
        </h1>
	<h1 t="Building Your Own">
		<p>But there may be times when it is simpler to deploy a new application for your workflow. This might be because you don't like Vaadin as
		a UI or perhaps you want to deploy smaller applications to specific user groups, and perhaps you aren't even bothered
		about using bundles to hold the forms. Maybe you want a very cut down app that someone can run on a tablet. In that case all you really need is a way for them to scan the PROCESSINSTANCE table for
		records that are in WAIT state and whose Queue Name is the one they are to access. Once they find one they should do the following:</p>
		<list>
		<le>Lock the process instance using your chosen lock mechanism eg SQLLock.</le>
		<le>Change the status to BUSY and write the current user name into the LockedBy field.</le>
		<le>Save the record.</le>
		<le>Release the lock.</le>
		<le>Fetch the context information eg the Order or whatever object structure is associated with this process definition.</le>
		<le>Present a form or some kind of input facility for the user to complete and have them indicate when they are done.</le>
		<le>Lock the process instance (again).</le>
		<le>Save the updated context and update the PROCESSINSTANCE status to GO and clear the lockedBy field. This should be a 2 phase commit.</le>
		<le>Release the lock.</le>
		</list>
		<p>That assumes you have the scheduler running in some other application, perhaps this one or a modified version of it. The scheduler
		application will ensure the process instances move through the process definition while keeping the above application as simple as possible.</p>
	</h1>
			
	<a1 t="License">
		<p>The code specific to Madura Workflow Impl is licensed under the Apache License 2.0 <referenceLink t="Apache Licence 2.0"/>.</p>
		<p>The dependent products have compatible licenses specified in their pom files. Madura Rules (optional) has a dual
		license to cover projects that do not qualify for the Apache License.</p>
	</a1>
		<a1 t="Release Notes">
			<table width="12cm">
				<tw>12cm</tw>
			<tr>
				<th>2.1.2</th>
			</tr>
			<tr>
				<td>Verified JMX working.</td>
			</tr>
			<tr>
				<td>Implemented SQLLocks.</td>
			</tr>
			<tr>
				<td>Added options for MySQL.</td>
			</tr>
			<tr>
				<td>Added Dockerfile.</td>
			</tr>
			<tr>
				<td>Changed the JNDI reference to bundles directory to a config.properties value.</td>
			</tr>
			<tr>
				<td>Renamed to Impl from ui because it will soon run (optionally) headless.</td>
			</tr>
			<tr>
				<td>Added conditional instantiation of scheduler to allow UI to not schedule.</td>
			</tr>
			<tr>
				<th>2.1.1</th>
			</tr>
			<tr>
				<td>Aligning with madura-workflows version.</td>
			</tr>
			<tr>
				<th>1.0.1</th>
			</tr>
			<tr>
				<td>No actual changes, just a problem with tags.</td>
			</tr>
			<tr>
				<th>1.0.0</th>
			</tr>
			<tr>
				<td>Initial version.</td>
			</tr>
			</table>
		</a1>
	</body>
</doc>
